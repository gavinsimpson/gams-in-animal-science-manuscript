@UNPUBLISHED{Henderson1990-bd,
  title = {Transform or Link},
  author = {Henderson, H V and McCulloch, C},
  date = {1990-06-01},
  year = {1990},
  url = {https://ecommons.cornell.edu/bitstream/1813/31620/1/BU-1049-MA.pdf},
  urldate = {2025-06-26}
}
@ARTICLE{Wood1967-re,
  title = {Algebraic model of the lactation curve in cattle},
  author = {Wood, P D P},
  journal = {Nature},
  publisher = {Springer Science and Business Media LLC},
  volume = {216},
  issue = {5111},
  pages = {164-165},
  date = {1967-10},
  year = {1967},
  doi = {10.1038/216164a0},
  issn = {0028-0836,1476-4687},
  abstract = {MANY factors may influence the total milk yield of a single
  lactation, but the general shape of the curve, defined by the locus of weekly
  yield, remains substantially unchanged. Economically, the configuration of the
  curve is important, for the animal which produces milk at a moderate level
  steadily throughout her lactation is to be preferred to one which produces a
  great deal of milk at her peak but little thereafter (see Cersovsky1 for a
  review of the literature).},
  url = {http://dx.doi.org/10.1038/216164a0},
  urldate = {2025-06-26},
  file = {All Papers/W/Wood 1967 - Algebraic model of the lactation curve in cattle.pdf},
  keywords = {Lactation curves;Animal Science},
  language = {en}
}
@MANUAL{Rcore,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2025},
  url = {https://www.R-project.org/},
}
@MANUAL{Wood2025-zt,
  type = {software},
  title = {mgcv: Mixed GAM computation vehicle with automatic smoothness
  estimation},
  author = {Wood, Simon N},
  publisher = {The R Foundation},
  date = {2025-04-04},
  year = {2025},
  doi = {10.32614/cran.package.mgcv},
  url = {http://dx.doi.org/10.32614/cran.package.mgcv},
  version = {1.9.3}
}
@ARTICLE{Wood2011-kn,
  title = {Fast stable restricted maximum likelihood and marginal likelihood
  estimation of semiparametric generalized linear models},
  author = {Wood, Simon N},
  journal = {J. R. Stat. Soc. Series B Stat. Methodol.},
  publisher = {Blackwell Publishing Ltd},
  volume = {73},
  issue = {1},
  pages = {3-36},
  date = {2011-01-01},
  year = {2011},
  doi = {10.1111/j.1467-9868.2010.00749.x},
  issn = {1369-7412,1467-9868},
  abstract = {Summary. Recent work by Reiss and Ogden provides a theoretical
  basis for sometimes preferring restricted maximum likelihood (REML) to
  generalized cross-validation (GCV) for smoothing parameter selection in
  semiparametric regression. However, existing REML or marginal likelihood (ML)
  based methods for semiparametric generalized linear models (GLMs) use
  iterative REML or ML estimation of the smoothing parameters of working linear
  approximations to the GLM. Such indirect schemes need not converge and fail to
  do so in a non-negligible proportion of practical analyses. By contrast, very
  reliable prediction error criteria smoothing parameter selection methods are
  available, based on direct optimization of GCV, or related criteria, for the
  GLM itself. Since such methods directly optimize properly defined functions of
  the smoothing parameters, they have much more reliable convergence properties.
  The paper develops the first such method for REML or ML estimation of
  smoothing parameters. A Laplace approximation is used to obtain an approximate
  REML or ML for any GLM, which is suitable for efficient direct optimization.
  This REML or ML criterion requires that Newton–Raphson iteration, rather than
  Fisher scoring, be used for GLM fitting, and a computationally stable approach
  to this is proposed. The REML or ML criterion itself is optimized by a Newton
  method, with the derivatives required obtained by a mixture of implicit
  differentiation and direct methods. The method will cope with numerical rank
  deficiency in the fitted model and in fact provides a slight improvement in
  numerical robustness on the earlier method of Wood for prediction error
  criteria based smoothness selection. Simulation results suggest that the new
  REML and ML methods offer some improvement in mean-square error performance
  relative to GCV or Akaike's information criterion in most cases, without the
  small number of severe undersmoothing failures to which Akaike's information
  criterion and GCV are prone. This is achieved at the same computational cost
  as GCV or Akaike's information criterion. The new approach also eliminates the
  convergence failures of previous REML- or ML-based approaches for penalized
  GLMs and usually has lower computational cost than these alternatives. Example
  applications are presented in adaptive smoothing, scalar on function
  regression and generalized additive model selection.},
  url = {http://dx.doi.org/10.1111/j.1467-9868.2010.00749.x},
  file = {All Papers/W/Wood 2011 - Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models.pdf},
  keywords = {Adaptive smoothing, Generalized additive mixed model, Generalized
  additive model, Generalized cross-validation, Marginal likelihood, Model
  selection, Penalized generalized linear model, Penalized regression splines,
  Restricted maximum likelihood, Scalar on function regression, Stable
  computation;May 29 import;Statistics;Additive Models}
}
@ARTICLE{Franchi2023-xq,
  title = {Estimating body weight in conventional growing pigs using a depth
  camera},
  author = {Franchi, Guilherme A and Bus, Jacinta D and Boumans, Iris J M M and
  Bokkers, Eddie A M and Jensen, Margit Bak and Pedersen, Lene Juul},
  journal = {Smart Agric. Technol.},
  publisher = {Elsevier BV},
  volume = {3},
  issue = {100117},
  pages = {100117},
  date = {2023-02-01},
  year = {2023},
  doi = {10.1016/j.atech.2022.100117},
  issn = {2772-3755},
  abstract = {Automated body weight (BW) estimation can be a useful tool for
  continuous monitoring of growth in commercial pigs, whereas deviations could
  indicate w…},
  url = {http://dx.doi.org/10.1016/j.atech.2022.100117},
  urldate = {2025-06-26},
  file = {All Papers/F/Franchi et al. 2023 - Estimating body weight in conventional growing pigs using a depth camera.pdf},
  keywords = {Animal Science},
  language = {en}
}
@ARTICLE{Bus2025-gg,
  title = {Short-term associations between ambient ammonia concentrations and
  growing-finishing pig performance and health},
  author = {Bus, Jacinta D and Franchi, Guilherme A and Boumans, Iris J M M and
  Te Beest, Dennis E and Webb, Laura E and Jensen, Margit Bak and Pedersen, Lene
  Juul and Bokkers, Eddie A M},
  journal = {Prev. Vet. Med.},
  publisher = {Elsevier BV},
  volume = {242},
  issue = {106555},
  pages = {106555},
  date = {2025-05-05},
  year = {2025},
  doi = {10.1016/j.prevetmed.2025.106555},
  pmid = {40375409},
  issn = {0167-5877,1873-1716},
  abstract = {Using sensors, the health and welfare of growing-finishing pigs
  can be continuously monitored by detecting deviations from pigs' normal
  behaviour, but the validity of such algorithms requires improvement. As
  changes in the environment influence pig behaviour, monitoring temporal
  changes in environmental factors may help identify periods with a higher risk
  of welfare issues. The real-time relationships between pig welfare and many
  environmental factors are, however, not well-understood. This study examined
  the short-term associations of ambient ammonia with indicators of pig
  production and health. Ambient ammonia concentrations were monitored with
  sensors during the growing-finishing period of three rounds at a German (farm
  G, n = 110 pigs/round) and one round at a Danish farm (farm D, n = 144 pigs).
  Body weight was estimated daily using 3D cameras (both farms), feed intake was
  recorded using electronic feeding stations (only farm G), and health
  indicators were recorded during twice- (farm G) or thrice-weekly (farm D) farm
  visits. Using splines (generalised additive models), ammonia concentrations
  were linked to indicators of pig production and health in real time and, for
  body weight, at a lag of 1, 2, 3 and 7 d. We found a range of relationships
  between ambient ammonia (5 - 50 ppm) and production or health indicators (i.e.
  body weight (real-time and lagged), feed intake, coughing, sneezing, pen
  fouling, diarrhoea, and tear staining), but they were highly inconsistent
  between farms and pig rounds. Part of this inconsistency may be due to
  differences in manure management and sensor locations, or could be explained
  by age or seasonal effects (e.g. heat stress). More robust relationships were
  identified for clinical measures related to pig behaviour, where tail damage
  and skin lesions linearly increased with ammonia from low concentrations (5 -
  10 ppm) onwards, hence suggesting more tail biting and aggression at higher
  ammonia concentrations. In conclusion, ambient ammonia did not clearly
  associate with pig performance and health in the short term, while higher
  ammonia concentrations were related to higher occurrences of clinical signs
  reflecting undesirable behaviours. Therefore, daily ammonia measurements using
  sensors may be of limited value in identifying health issues in pigs, but they
  may aid in detecting periods with high risk of aggressive or tail biting
  behaviours that require interventions. As ambient ammonia was confounded with
  other environmental measurements, such as ambient temperature or carbon
  dioxide concentrations, identified associations should be interpreted
  cautiously or with ammonia as general indicator of air quality.},
  url = {http://dx.doi.org/10.1016/j.prevetmed.2025.106555},
  urldate = {2025-06-17},
  file = {All Papers/B/Bus et al. 2025 - Short-term associations between ambient ammonia concentrations and growing-finishing pig performance and health.pdf},
  keywords = {Precision Livestock Farming (PLF); air pollutants; animal welfare;
  barn climate; generalised additive models;Animal Science},
  language = {en}
}
@ARTICLE{Pedersen2019-ff,
  title = {Hierarchical generalized additive models in ecology: an introduction
  with mgcv},
  author = {Pedersen, Eric J and Miller, David L and Simpson, Gavin L and Ross,
  Noam},
  journal = {PeerJ},
  publisher = {PeerJ Inc.},
  volume = {7},
  pages = {e6876},
  date = {2019-05-27},
  year = {2019},
  doi = {10.7717/peerj.6876},
  pmc = {PMC6542350},
  pmid = {31179172},
  issn = {2167-8359},
  abstract = {In this paper, we discuss an extension to two popular approaches
  to modeling complex structures in ecological data: the generalized additive
  model (GAM) and the hierarchical model (HGLM). The hierarchical GAM (HGAM),
  allows modeling of nonlinear functional relationships between covariates and
  outcomes where the shape of the function itself varies between different
  grouping levels. We describe the theoretical connection between HGAMs, HGLMs,
  and GAMs, explain how to model different assumptions about the degree of
  intergroup variability in functional response, and show how HGAMs can be
  readily fitted using existing GAM software, the mgcv package in R. We also
  discuss computational and statistical issues with fitting these models, and
  demonstrate how to fit HGAMs on example data. All code and data used to
  generate this paper are available at:
  github.com/eric-pedersen/mixed-effect-gams.},
  url = {http://dx.doi.org/10.7717/peerj.6876},
  urldate = {2019-05-27},
  file = {All Papers/P/Pedersen et al. 2019 - Hierarchical generalized additive models in ecology - an introduction with mgcv.pdf},
  keywords = {Generalized additive models; Hierarchical models; Time series;
  Functional regression; Smoothing; Regression; Community ecology; Tutorial;
  Nonlinear estimation;Additive Models;Counts;Ecology;Functional
  modelling;GLMs;Mixed models;Spatial;Spatiotemporal;Splines;Statistics},
  language = {en}
}
@ARTICLE{Morota2021-jz,
  title = {ASAS-NANP SYMPOSIUM: prospects for interactive and dynamic graphics
  in the era of data-rich animal science1},
  author = {Morota, Gota and Cheng, Hao and Cook, Dianne and Tanaka, Emi},
  journal = {J. Anim. Sci.},
  volume = {99},
  issue = {2},
  date = {2021-02-01},
  year = {2021},
  doi = {10.1093/jas/skaa402},
  pmc = {PMC7904041},
  pmid = {33626150},
  issn = {0021-8812,1525-3163},
  abstract = {Statistical graphics, and data visualization, play an essential
  but under-utilized, role for data analysis in animal science, and also to
  visually illustrate the concepts, ideas, or outputs of research and in
  curricula. The recent rise in web technologies and ubiquitous availability of
  web browsers enables easier sharing of interactive and dynamic graphics.
  Interactivity and dynamic feedback enhance human-computer interaction and data
  exploration. Web applications such as decision support systems coupled with
  multimedia tools synergize with interactive and dynamic graphics. However, the
  importance of graphics for effectively communicating data, understanding data
  uncertainty, and the state of the field of interactive and dynamic graphics is
  underappreciated in animal science. To address this gap, we describe the
  current state of graphical methodology and technology that might be more
  broadly adopted. This includes an explanation of a conceptual framework for
  effective graphics construction. The ideas and technology are illustrated
  using publicly available animal datasets. We foresee that many new types of
  big and complex data being generated in precision livestock farming create
  exciting opportunities for applying interactive and dynamic graphics to
  improve data analysis and make data-supported decisions.},
  url = {http://dx.doi.org/10.1093/jas/skaa402},
  file = {All Papers/M/Morota et al. 2021 - ASAS-NANP SYMPOSIUM - prospects for interactive and dynamic graphics in the era of data-rich animal science1.pdf},
  keywords = {dynamic graphic; human–computer interaction; image; interactive
  graphic; statistical graphic; visualization;Animal Science BSc;Animal
  Science;Statistics;Data visualisation},
  language = {en}
}
@DATASET{Sarraude2020-cw,
  title = {Dataset of prenatal thyroid hormones manipulation in Japanese quails},
  author = {Sarraude, Tom and Hsu, Bin-Yan and Groothuis, Ton and Ruuskanen,
  Suvi},
  date = {2020-04-06},
  year = {2020},
  doi = {10.5281/zenodo.3741711},
  url = {https://zenodo.org/record/3741711}
}

@ARTICLE{Sarraude2020-fu,
  title = {Testing the short-and long-term effects of elevated prenatal exposure
  to different forms of thyroid hormones},
  author = {Sarraude, Tom and Hsu, Bin-Yan and Groothuis, Ton and Ruuskanen,
  Suvi},
  journal = {PeerJ},
  volume = {8},
  pages = {e10175},
  date = {2020-10-16},
  year = {2020},
  doi = {10.7717/peerj.10175},
  pmc = {PMC7571413},
  pmid = {33088630},
  issn = {2167-8359},
  abstract = {Maternal thyroid hormones (THs) are known to be crucial in
  embryonic development in humans, but their influence on other, especially
  wild, animals remains poorly understood. So far, the studies that
  experimentally investigated the consequences of maternal THs focused on
  short-term effects, while early organisational effects with long-term
  consequences, as shown for other prenatal hormones, could also be expected. In
  this study, we aimed at investigating both the short- and long-term effects of
  prenatal THs in a bird species, the Japanese quail Coturnix japonica. We
  experimentally elevated yolk TH content (the prohormone T4, and its active
  metabolite T3, as well as a combination of both hormones). We analysed
  hatching success, embryonic development, offspring growth and oxidative stress
  as well as their potential organisational effects on reproduction, moult and
  oxidative stress in adulthood. We found that eggs injected with T4 had a
  higher hatching success compared with control eggs, suggesting conversion of
  T4 into T3 by the embryo. We detected no evidence for other short-term or
  long-term effects of yolk THs. These results suggest that yolk THs are
  important in the embryonic stage of precocial birds, but other short- and
  long-term consequences remain unclear. Research on maternal THs will greatly
  benefit from studies investigating how embryos use and respond to this
  maternal signalling. Long-term studies on prenatal THs in other taxa in the
  wild are needed for a better understanding of this hormone-mediated maternal
  pathway.},
  url = {http://dx.doi.org/10.7717/peerj.10175},
  file = {All Papers/S/Sarraude et al. 2020 - Testing the short-and long-term effects of elevated prenatal exposure to different forms of thyroid hormones.pdf},
  keywords = {Avian growth; Hatching success; Japanese quails; Life-history
  strategies; Maternal hormones; Thyroid hormones},
  language = {en}
}
@ARTICLE{Miller2025-bd,
  title = {Bayesian views of generalized additive modelling},
  author = {Miller, David L},
  journal = {Methods Ecol. Evol.},
  publisher = {Wiley},
  date = {2025-01-24},
  year = {2025},
  doi = {10.1111/2041-210x.14498},
  issn = {2041-210X},
  abstract = {Abstract Generalized additive models (GAMs) are a frequently used,
  flexible framework applied to many problems in statistical ecology. They are
  commonly used to incorporate smooth effects into models via splines, including
  spatial components in species distribution models. GAMs are often considered
  to be a purely frequentist framework (‘generalized linear models with wiggly
  bits’), however links between frequentist and Bayesian approaches to these
  models were highlighted early‐on in the literature. From a practical
  perspective, Bayesian thinking underlies many parts of the implementation in
  the popular R package mgcv, so understanding these underpinnings can be
  informative during model building and assessment. This article aims to
  highlight useful links (and differences) between Bayesian and frequentist
  approaches to smoothing, as detailed in the statistical literature, in
  accessible way, with a focus on the mgcv implementation. By harnessing these
  links we can expand the set of modelling tools we have at our disposal, as
  well as our understanding of how existing methods work. Two important topics
  for quantitative ecologists are covered in detail: model term selection and
  uncertainty estimation. Taking Bayesian viewpoints for these problems makes
  them much more tractable in many applied settings. Examples are given using
  data from the NOAA Alaska Fisheries Science Center's groundfish assessment
  program.},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.14498},
  urldate = {2025-01-30},
  file = {All Papers/M/Miller 2025 - Bayesian views of generalized additive modelling.pdf},
  keywords = {basis-penalty smoothers; empirical Bayes; random effects;
  smoothers;Bayesian;Additive Models;Statistics},
  language = {en}
}
@ARTICLE{Reiss2009-fk,
  title = {Smoothing parameter selection for a class of semiparametric linear
  models},
  author = {Reiss, Philip T and Ogden, R Todd},
  journal = {J. R. Stat. Soc. Series B Stat. Methodol.},
  volume = {71},
  issue = {2},
  pages = {505-523},
  year = {2009},
  doi = {10.1111/j.1467-9868.2008.00695.x},
  issn = {1369-7412,1467-9868},
  abstract = {Summary.? Spline?based approaches to non?parametric and
  semiparametric regression, as well as to regression of scalar outcomes on
  functional predictors, entail choosing a parameter controlling the extent to
  which roughness of the fitted function is penalized. We demonstrate that the
  equations determining two popular methods for smoothing parameter selection,
  generalized cross?validation and restricted maximum likelihood, share a
  similar form that allows us to prove several results which are common to both,
  and to derive a condition under which they yield identical values. These ideas
  are illustrated by application of functional principal component regression, a
  method for regressing scalars on functions, to two chemometric data sets.},
  url = {http://doi.wiley.com/10.1111/j.1467-9868.2008.00695.x},
  file = {All Papers/R/Reiss and Ogden 2009 - Smoothing parameter selection for a class of semiparametric linear models.pdf},
  keywords = {Additive Models}
}
@ARTICLE{Benjamini2001-kh,
  title = {The control of the false discovery rate in multiple testing under
  dependency},
  author = {Benjamini, Yoav and Yekutieli, Daniel},
  journal = {Ann. Stat.},
  publisher = {Institute of Mathematical Statistics},
  volume = {29},
  issue = {4},
  pages = {1165-1188},
  date = {2001-08},
  year = {2001},
  issn = {0090-5364,2168-8966},
  abstract = {Project Euclid - mathematics and statistics online},
  url = {http://projecteuclid.org/download/pdf_1/euclid.aos/1013699998},
  urldate = {2015-12-10},
  file = {All Papers/B/Benjamini and Yekutieli 2001 - The control of the false discovery rate in multiple testing under dependency.pdf},
  keywords = {Multiple comparisons procedures; FDR; Simes’equality; Hochberg’s
  procedure; MTP2 densities; positive regression dependency; unidimensional
  latent variables; discrete test statistics; multiple endpoints many-to-one
  comparisons; comparisons with control}
}
@ARTICLE{Arel-Bundock2024-nw,
  title = {How to Interpret Statistical Models Using marginaleffects for
  \textit{R} and \textit{Python}},
  author = {Arel-Bundock, Vincent and Greifer, Noah and Heiss, Andrew},
  journal = {J. Stat. Softw.},
  publisher = {Foundation for Open Access Statistic},
  volume = {111},
  issue = {9},
  pages = {1-32},
  date = {2024-11-30},
  year = {2024},
  doi = {10.18637/jss.v111.i09},
  issn = {1548-7660,1548-7660},
  abstract = {The parameters of a statistical model can sometimes be difficult
  to interpret substantively, especially when that model includes nonlinear
  components, interactions, or transformations. Analysts who fit such complex
  models often seek to transform raw parameter estimates into quantities that
  are easier for domain experts and stakeholders to understand. This article
  presents a simple conceptual framework to describe a vast array of such
  quantities of interest, which are reported under imprecise and inconsistent
  terminology across disciplines: predictions, marginal predictions, marginal
  means, marginal effects, conditional effects, slopes, contrasts, risk ratios,
  etc. We introduce marginaleffects, a package for R and Python which offers a
  simple and powerful interface to compute all of those quantities, and to
  conduct (non-)linear hypothesis and equivalence tests on them. marginaleffects
  is lightweight; extensible; it works well in combination with other R and
  Python packages; and it supports over 100 classes of models, including linear,
  generalized linear, generalized additive, mixed effects, Bayesian, and several
  machine learning models.},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v111i09},
  urldate = {2024-12-06},
  file = {All Papers/A/Arel-Bundock et al. 2024 - How to Interpret Statistical Models Using marginaleffects for R and Python.pdf},
  language = {en}
}
@ARTICLE{Simpson2024-ml,
  title = {gratia: An {R} package for exploring generalized additive models},
  author = {Simpson, Gavin L},
  journal = {J. Open Source Softw.},
  publisher = {The Open Journal},
  volume = {9},
  issue = {104},
  pages = {6962},
  date = {2024-12-21},
  year = {2024},
  doi = {10.21105/joss.06962},
  issn = {2475-9066},
  abstract = {Simpson, G. L., (2024). gratia: An R package for exploring
  generalized additive models. Journal of Open Source Software, 9(104), 6962,
  https://doi.org/10.21105/joss.06962},
  url = {https://joss.theoj.org/papers/10.21105/joss.06962},
  urldate = {2025-01-27},
  file = {All Papers/S/Simpson 2024 - gratia - An R package for exploring generalized additive models.pdf},
  keywords = {Additive Models}
}
@BOOK{Wickham2016-dg,
  title = {ggplot2: Elegant Graphics for Data Analysis},
  author = {Wickham, Hadley},
  publisher = {Springer International Publishing},
  date = {2016},
  year = {2016},
  doi = {10.1007/978-3-319-24277-4},
  isbn = {9783319242750,9783319242774},
  series = {Use R!},
  url = {https://link.springer.com/book/10.1007/978-3-319-24277-4},
  file = {All Papers/W/Wickham 2016 - ggplot2 - Elegant Graphics for Data Analysis.pdf},
  keywords = {Books}
}
@ARTICLE{Li2020-ch,
  title = {Faster model matrix crossproducts for large generalized linear models
  with discretized covariates},
  author = {Li, Zheyuan and Wood, Simon N},
  journal = {Stat. Comput.},
  publisher = {Springer Science and Business Media LLC},
  volume = {30},
  issue = {1},
  pages = {19-25},
  date = {2020-02},
  year = {2020},
  doi = {10.1007/s11222-019-09864-2},
  issn = {0960-3174,1573-1375},
  abstract = {Wood et al. (J Am Stat Assoc 112(519):1199–1210, 2017) developed
  methods for fitting penalized regression spline based generalized additive
  models, with of the order of $$10\textasciicircum4$$104coefficients, to up to
  $$10\textasciicircum8$$108data. The methods offered two to three orders of
  magnitude reduction in computational cost relative to the most efficient
  previous methods. Part of the gain resulted from the development of a set of
  methods for efficiently computing model matrix products when model covariates
  each take only a discrete set of values substantially smaller than the sample
  size [generalizing an idea first appearing in Lang et al. (Stat Comput
  24(2):223–238, 2014)]. Covariates can always be rounded to achieve such
  discretization, and it should be noted that the covariate discretization is
  marginal. That is we do not rely on discretizing covariates jointly, which
  would typically require the use of very coarse discretization. The most
  expensive computation in model estimation is the formation of the matrix cross
  product $$\mathbf{X}\textasciicircum{\mathsf{T}}{\mathbf{WX}}$$XTWXwhere
  $$\mathbf{X}$$Xis a model matrix and $${\mathbf{W}}$$Wa diagonal or
  tri-diagonal matrix. The purpose of this paper is to present a simple, novel
  and substantially more efficient approach to the computation of this cross
  product. The new method offers, for example, a 30 fold reduction in cross
  product computation time for the Black Smoke model dataset motivating Wood et
  al. (2017). Given this reduction in computational cost, the subsequent
  Cholesky decomposition of
  $$\mathbf{X}\textasciicircum{\mathsf{T}}{\mathbf{WX}}$$XTWXand follow on
  computation of
  $$(\mathbf{X}\textasciicircum{\mathsf{T}}{\mathbf{WX}})\textasciicircum{-1}$$(XTWX)-1become
  a more significant part of the computational burden, and we also discuss the
  choice of methods for improving their speed.},
  url = {https://doi.org/10.1007/s11222-019-09864-2},
  file = {All Papers/L/Li and Wood 2020 - Faster model matrix crossproducts for large generalized linear models with discretized covariates.pdf},
  language = {en}
}
@ARTICLE{Pya2016-rk,
  title = {A note on basis dimension selection in generalized additive modelling},
  author = {Pya, Natalya and Wood, Simon N},
  journal = {arXiv [stat.ME]},
  date = {2016-02-22},
  year = {2016},
  eprint = {1602.06696},
  eprinttype = {arXiv},
  eprintclass = {stat.ME},
  abstract = {Two new approaches for checking the dimension of the basis
  functions when using penalized regression smoothers are presented. The first
  approach is a test for adequacy of the basis dimension based on an estimate of
  the residual variance calculated by differencing residuals that are neighbours
  according to the smooth covariates. The second approach is based on estimated
  degrees of freedom for a smooth of the model residuals with respect to the
  model covariates. In comparison with basis dimension selection algorithms
  based on smoothness selection criterion (GCV, AIC, REML) the above procedures
  are computationally efficient enough for routine use as part of model
  checking.},
  url = {http://arxiv.org/abs/1602.06696},
  file = {All Papers/P/Pya and Wood 2016 - A note on basis dimension selection in generalized additive modelling.pdf},
  keywords = {Additive Models}
}
@ARTICLE{Wood2016-fx,
  title = {Smoothing Parameter and Model Selection for General Smooth Models},
  author = {Wood, Simon N and Pya, Natalya and Säfken, Benjamin},
  journal = {J. Am. Stat. Assoc.},
  publisher = {Taylor \& Francis},
  volume = {111},
  issue = {516},
  pages = {1548-1563},
  date = {2016-10-01},
  year = {2016},
  eprint = {http://dx.doi.org/10.1080/01621459.2016.1180986},
  doi = {10.1080/01621459.2016.1180986},
  issn = {0162-1459},
  abstract = {ABSTRACTThis article discusses a general framework for smoothing
  parameter estimation for models with regular likelihoods constructed in terms
  of unknown smooth functions of covariates. Gaussian random effects and
  parametric terms may also be present. By construction the method is
  numerically stable and convergent, and enables smoothing parameter uncertainty
  to be quantified. The latter enables us to fix a well known problem with AIC
  for such models, thereby improving the range of model selection tools
  available. The smooth functions are represented by reduced rank spline like
  smoothers, with associated quadratic penalties measuring function smoothness.
  Model estimation is by penalized likelihood maximization, where the smoothing
  parameters controlling the extent of penalization are estimated by Laplace
  approximate marginal likelihood. The methods cover, for example, generalized
  additive models for nonexponential family responses (e.g., beta, ordered
  categorical, scaled t distribution, negative binomial and Tweedie
  distributions), generalized additive models for location scale and shape
  (e.g., two stage zero inflation models, and Gaussian location-scale models),
  Cox proportional hazards models and multivariate additive models. The
  framework reduces the implementation of new model classes to the coding of
  some standard derivatives of the log-likelihood. Supplementary materials for
  this article are available online.},
  url = {https://doi.org/10.1080/01621459.2016.1180986},
  note = {doi: 10.1080/01621459.2016.1180986},
  file = {All Papers/W/Wood et al. 2016 - uasa_a_1180986_sm0752.pdf;All Papers/W/Wood et al. 2016 - Smoothing Parameter and Model Selection for General Smooth Models.pdf;All Papers/W/Wood et al. 2016 - Smoothing Parameter and Model Selection for General Smooth Models.pdf;All Papers/W/Wood et al. 2016 - uasa_a_1180986_sm9350.pdf},
  keywords = {Additive Models;Statistics;Variance;Likelihood;GLMs;Negative
  Binomial}
}
@ARTICLE{Klein2024-im,
  title = {Distributional regression for data analysis},
  author = {Klein, Nadja},
  journal = {Annu. Rev. Stat. Appl.},
  publisher = {Annual Reviews},
  volume = {11},
  issue = {1},
  date = {2024-03-07},
  year = {2024},
  doi = {10.1146/annurev-statistics-040722-053607},
  issn = {2326-8298,2326-831X},
  abstract = {Flexible modeling of how an entire distribution changes with
  covariates is an important yet challenging generalization of mean-based
  regression that has seen growing interest over the past decades in both the
  statistics and machine learning literature. This review outlines selected
  state-of-the-art statistical approaches to distributional regression,
  complemented with alternatives from machine learning. Topics covered include
  the similarities and differences between these approaches, extensions,
  properties and limitations, estimation procedures, and the availability of
  software. In view of the increasing complexity and availability of large-scale
  data, this review also discusses the scalability of traditional estimation
  methods, current trends, and open challenges. Illustrations are provided using
  data on childhood malnutrition in Nigeria and Australian electricity prices.
  Expected final online publication date for the Annual Review of Statistics and
  Its Application, Volume 11 is March 2024. Please see
  http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
  url = {https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-040722-053607},
  urldate = {2024-03-22},
  keywords = {GAM Book;Additive Models;Distributional regression;Statistics},
  language = {en}
}

@ARTICLE{Kneib2021-zb,
  title = {Rage Against the Mean – A Review of Distributional Regression
  Approaches},
  author = {Kneib, Thomas and Silbersdorff, Alexander and Säfken, Benjamin},
  journal = {Econometrics and Statistics},
  date = {2021-08-10},
  year = {2021},
  doi = {10.1016/j.ecosta.2021.07.006},
  issn = {2452-3062},
  abstract = {Distributional regression models that overcome the traditional
  focus on relating the conditional mean of the response to explanatory
  variables and instead target either the complete conditional response
  distribution or more general features thereof have seen increasing interest in
  the past decade. The current state of distributional regression will be
  discussed, with a particular focus on the four most prominent model classes:
  (i) generalized additive models for location, scale and shape, (ii)
  conditional transformation models and distribution regression, (iii) density
  regression, and (iv) quantile and expectile regression. Characteristics of the
  different distributional regression approaches will be provided to establish a
  structured overview on the similarities and differences with respect to the
  required assumptions on the conditional response distribution, theoretical
  properties, and the availability of software implementations. In addition,
  challenges arising in the interpretability of distributional regression models
  will be discussed and all four approaches will be illustrated with an
  application analyzing determinants of income distributions from the German
  Socio-Economic Panel (GSOEP).},
  url = {https://www.sciencedirect.com/science/article/pii/S2452306221000824},
  file = {All Papers/K/Kneib et al. 2021 - Rage Against the Mean – A Review of Distributional Regression Approaches.pdf},
  keywords = {Conditional transformation models; Density regression;
  Distribution regression; Expectile regression; Generalized additive models for
  location; Scale and shape; Quantile regression;Distributional
  regression;Statistics}
}
@ARTICLE{Rigby2005-nl,
  title = {Generalized additive models for location, scale and shape},
  author = {Rigby, R A and Stasinopoulos, D M},
  journal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  publisher = {Blackwell Publishing Ltd},
  volume = {54},
  issue = {3},
  pages = {507-554},
  date = {2005-06-01},
  year = {2005},
  doi = {10.1111/j.1467-9876.2005.00510.x},
  issn = {0035-9254,1467-9876},
  abstract = {Summary. A general class of statistical models for a univariate
  response variable is presented which we call the generalized additive model
  for location, scale and shape (GAMLSS). The model assumes independent
  observations of the response variable y given the parameters, the explanatory
  variables and the values of the random effects. The distribution for the
  response variable in the GAMLSS can be selected from a very general family of
  distributions including highly skew or kurtotic continuous and discrete
  distributions. The systematic part of the model is expanded to allow modelling
  not only of the mean (or location) but also of the other parameters of the
  distribution of y, as parametric and/or additive nonparametric (smooth)
  functions of explanatory variables and/or random-effects terms. Maximum
  (penalized) likelihood estimation is used to fit the (non)parametric models. A
  Newton–Raphson or Fisher scoring algorithm is used to maximize the (penalized)
  likelihood. The additive terms in the model are fitted by using a backfitting
  algorithm. Censored data are easily incorporated into the framework. Five data
  sets from different fields of application are analysed to emphasize the
  generality of the GAMLSS class of models.},
  url = {http://dx.doi.org/10.1111/j.1467-9876.2005.00510.x},
  file = {All Papers/R/Rigby and Stasinopoulos 2005 - Generalized additive models for location, scale and shape.pdf},
  keywords = {Beta–binomial distribution; Box–Cox transformation; Centile
  estimation; Cubic smoothing splines; Generalized linear mixed model; LMS
  method; Negative binomial distribution; Non-normality; Nonparametric models;
  Overdispersion; Penalized likelihood; Random effects; Skewness and
  kurtosis;Additive Models;Statistics;Variance;GLMs}
}

@ARTICLE{van-Lingen2023-sd,
  title = {Smoothing spline assessment of the accuracy of enteric hydrogen and
  methane production measurements from dairy cattle using various sampling
  schemes},
  author = {van Lingen, Henk J and Fadel, James G and Kebreab, Ermias and
  Bannink, André and Dijkstra, Jan and van Gastelen, Sanne},
  journal = {J. Dairy Sci.},
  publisher = {Elsevier},
  volume = {106},
  issue = {10},
  pages = {6834-6848},
  date = {2023-10-18},
  year = {2023},
  doi = {10.3168/jds.2022-23207},
  pmid = {37210350},
  issn = {0022-0302,1525-3198},
  abstract = {Estimating daily enteric hydrogen (H2) and methane (CH4) emitted
  from dairy cattle using spot sampling techniques requires accurate sampling
  schemes. These sampling schemes determine the number of daily samplings and
  their intervals. This simulation study assessed the accuracy of daily H2 and
  CH4 emissions from dairy cattle using various sampling schemes for gas
  collection. Gas emission data were available from a crossover experiment with
  28 cows fed twice daily at 80\% to 95\% of the ad libitum intake, and an
  experiment that used a repeated randomized block design with 16 cows twice
  daily fed ad libitum. Gases were sampled every 12 to 15 min for 3 consecutive
  days in climate respiration chambers. Feed was fed in 2 equal portions per day
  in both experiments. Per individual cow-period combination, generalized
  additive models were fitted to all diurnal H2 and CH4 emission profiles. Per
  profile, the models were fitted using the generalized cross-validation, REML,
  REML while assuming correlated residuals, and REML while assuming
  heteroscedastic residuals. The areas under the curve (AUC) of these 4 fits
  were numerically integrated over 24 h to compute the daily production and
  compared with the mean of all data points, which was considered the reference.
  Next, the best of the 4 fits was used to evaluate 9 different sampling
  schemes. This evaluation determined the average predicted values sampled at
  0.5, 1, and 2 h intervals starting at 0 h from morning feeding, at 1 and 2 h
  intervals starting at 0.5 h from morning feeding, at 6 and 8 h intervals
  starting at 2 h from morning feeding, and at 2 unequally spaced intervals with
  2 or 3 samples per day. Sampling every 0.5 h was needed to obtain daily H2
  productions not different from the selected AUC for the restricted feeding
  experiment, whereas less frequent sampling had predictions varying from 47\%
  to 233\% of the AUC. For the ad libitum feeding experiment, sampling schemes
  had H2 productions from 85\% to 155\% of the corresponding AUC. For the
  restricted feeding experiment, daily CH4 production needed samplings every 2 h
  or shorter, or 1 h or shorter, depending on sampling time after feeding,
  whereas sampling scheme did not affect CH4 production for the twice daily ad
  libitum feeding experiment. In conclusion, sampling scheme had a major impact
  on predicted daily H2 production, particularly with restricted feeding,
  whereas daily CH4 production was less severely affected by sampling scheme.},
  url = {http://dx.doi.org/10.3168/jds.2022-23207},
  urldate = {2023-05-23},
  file = {All Papers/V/van Lingen et al. 2023 - Smoothing spline assessment of the accuracy of ... duction measurements from dairy cattle using various sampling schemes.pdf},
  keywords = {ad libitum feeding; cow; diurnal profile; restricted feeding},
  language = {en}
}
@ARTICLE{Wood2003-qy,
  title = {Thin plate regression splines},
  author = {Wood, Simon N},
  journal = {J. R. Stat. Soc. Series B Stat. Methodol.},
  publisher = {Oxford University Press (OUP)},
  volume = {65},
  issue = {1},
  pages = {95-114},
  date = {2003-02-01},
  year = {2003},
  doi = {10.1111/1467-9868.00374},
  issn = {1369-7412,1467-9868},
  abstract = {Summary I discuss the production of low rank smoothers for d ≥ 1
  dimensional data, which can be fitted by regression or penalized regression
  methods. The smoothers are constructed by a simple transformation and
  truncation of the basis that arises from the solution of the thin plate spline
  smoothing problem and are optimal in the sense that the truncation is designed
  to result in the minimum possible perturbation of the thin plate spline
  smoothing problem given the dimension of the basis used to construct the
  smoother. By making use of Lanczos iteration the basis change and truncation
  are computationally efficient. The smoothers allow the use of approximate thin
  plate spline models with large data sets, avoid the problems that are
  associated with ‘knot placement’ that usually complicate modelling with
  regression splines or penalized regression splines, provide a sensible way of
  modelling interaction terms in generalized additive models, provide low rank
  approximations to generalized smoothing spline models, appropriate for use
  with large data sets, provide a means for incorporating smooth functions of
  more than one variable into non-linear models and improve the computational
  efficiency of penalized likelihood models incorporating thin plate splines.
  Given that the approach produces spline-like models with a sparse basis, it
  also provides a natural way of incorporating unpenalized spline-like terms in
  linear and generalized linear models, and these can be treated just like any
  other model terms from the point of view of model selection, inference and
  diagnostics.},
  url = {http://dx.doi.org/10.1111/1467-9868.00374},
  file = {All Papers/W/Wood 2003 - Thin plate regression splines - Thin Plate Regression Splines.pdf},
  keywords = {Generalized additive model; Regression spline; Thin plate spline},
  language = {en}
}
